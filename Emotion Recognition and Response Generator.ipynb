{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:45.029585Z",
     "iopub.status.busy": "2024-12-02T06:54:45.028790Z",
     "iopub.status.idle": "2024-12-02T06:54:46.100940Z",
     "shell.execute_reply": "2024-12-02T06:54:46.100304Z",
     "shell.execute_reply.started": "2024-12-02T06:54:45.029549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introducing the GoEmotion dataset and pre-processing to make it readily available for model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:46.102593Z",
     "iopub.status.busy": "2024-12-02T06:54:46.102273Z",
     "iopub.status.idle": "2024-12-02T06:54:46.277249Z",
     "shell.execute_reply": "2024-12-02T06:54:46.276589Z",
     "shell.execute_reply.started": "2024-12-02T06:54:46.102567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/kaggle/input/goemotions/data/train.tsv\", sep='\\t', header=None, names=['Text', 'Class', 'ID'])\n",
    "df_test = pd.read_csv(\"/kaggle/input/goemotions/data/test.tsv\", sep='\\t', header=None, names=['Text', 'Class', 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:46.279433Z",
     "iopub.status.busy": "2024-12-02T06:54:46.279048Z",
     "iopub.status.idle": "2024-12-02T06:54:46.299060Z",
     "shell.execute_reply": "2024-12-02T06:54:46.298122Z",
     "shell.execute_reply.started": "2024-12-02T06:54:46.279393Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>27</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>27</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>2</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>14</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>3</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43405</th>\n",
       "      <td>Added you mate well I‚Äôve just got the bow and ...</td>\n",
       "      <td>18</td>\n",
       "      <td>edsb738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43406</th>\n",
       "      <td>Always thought that was funny but is it a refe...</td>\n",
       "      <td>6</td>\n",
       "      <td>ee7fdou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43407</th>\n",
       "      <td>What are you talking about? Anything bad that ...</td>\n",
       "      <td>3</td>\n",
       "      <td>efgbhks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43408</th>\n",
       "      <td>More like a baptism, with sexy results!</td>\n",
       "      <td>13</td>\n",
       "      <td>ed1naf8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43409</th>\n",
       "      <td>Enjoy the ride!</td>\n",
       "      <td>17</td>\n",
       "      <td>eecwmbq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43410 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Class       ID\n",
       "0      My favourite food is anything I didn't have to...    27  eebbqej\n",
       "1      Now if he does off himself, everyone will thin...    27  ed00q6i\n",
       "2                         WHY THE FUCK IS BAYLESS ISOING     2  eezlygj\n",
       "3                            To make her feel threatened    14  ed7ypvh\n",
       "4                                 Dirty Southern Wankers     3  ed0bdzj\n",
       "...                                                  ...   ...      ...\n",
       "43405  Added you mate well I‚Äôve just got the bow and ...    18  edsb738\n",
       "43406  Always thought that was funny but is it a refe...     6  ee7fdou\n",
       "43407  What are you talking about? Anything bad that ...     3  efgbhks\n",
       "43408            More like a baptism, with sexy results!    13  ed1naf8\n",
       "43409                                    Enjoy the ride!    17  eecwmbq\n",
       "\n",
       "[43410 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:46.300310Z",
     "iopub.status.busy": "2024-12-02T06:54:46.300042Z",
     "iopub.status.idle": "2024-12-02T06:54:46.342816Z",
     "shell.execute_reply": "2024-12-02T06:54:46.341992Z",
     "shell.execute_reply.started": "2024-12-02T06:54:46.300276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train['List of classes'] = df_train['Class'].apply(lambda x: x.split(','))\n",
    "df_train['Len of classes'] = df_train['List of classes'].apply(lambda x: len(x))\n",
    "df_test['List of classes'] = df_test['Class'].apply(lambda x: x.split(','))\n",
    "df_test['Len of classes'] = df_test['List of classes'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mapping all annotated emotion set with core emotions using Ekman Mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:47.086946Z",
     "iopub.status.busy": "2024-12-02T06:54:47.086305Z",
     "iopub.status.idle": "2024-12-02T06:54:47.098202Z",
     "shell.execute_reply": "2024-12-02T06:54:47.097519Z",
     "shell.execute_reply.started": "2024-12-02T06:54:47.086914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('../input/goemotions/data/ekman_mapping.json') as file:\n",
    "    ekman_mapping = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:47.415952Z",
     "iopub.status.busy": "2024-12-02T06:54:47.415674Z",
     "iopub.status.idle": "2024-12-02T06:54:47.422012Z",
     "shell.execute_reply": "2024-12-02T06:54:47.421119Z",
     "shell.execute_reply.started": "2024-12-02T06:54:47.415927Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': ['anger', 'annoyance', 'disapproval'],\n",
       " 'disgust': ['disgust'],\n",
       " 'fear': ['fear', 'nervousness'],\n",
       " 'joy': ['joy',\n",
       "  'amusement',\n",
       "  'approval',\n",
       "  'excitement',\n",
       "  'gratitude',\n",
       "  'love',\n",
       "  'optimism',\n",
       "  'relief',\n",
       "  'pride',\n",
       "  'admiration',\n",
       "  'desire',\n",
       "  'caring'],\n",
       " 'sadness': ['sadness', 'disappointment', 'embarrassment', 'grief', 'remorse'],\n",
       " 'surprise': ['surprise', 'realization', 'confusion', 'curiosity']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ekman_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:47.612575Z",
     "iopub.status.busy": "2024-12-02T06:54:47.612322Z",
     "iopub.status.idle": "2024-12-02T06:54:47.623564Z",
     "shell.execute_reply": "2024-12-02T06:54:47.622736Z",
     "shell.execute_reply.started": "2024-12-02T06:54:47.612550Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "emotion_file = open(\"/kaggle/input/goemotions/data/emotions.txt\", \"r\")\n",
    "emotion_list = emotion_file.read()\n",
    "emotion_list = emotion_list.split(\"\\n\")\n",
    "print(emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:47.808976Z",
     "iopub.status.busy": "2024-12-02T06:54:47.808412Z",
     "iopub.status.idle": "2024-12-02T06:54:47.812761Z",
     "shell.execute_reply": "2024-12-02T06:54:47.811959Z",
     "shell.execute_reply.started": "2024-12-02T06:54:47.808950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def idx2class(idx_list):\n",
    "    arr = []\n",
    "    for i in idx_list:\n",
    "        arr.append(emotion_list[int(i)])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:47.951432Z",
     "iopub.status.busy": "2024-12-02T06:54:47.950811Z",
     "iopub.status.idle": "2024-12-02T06:54:48.044506Z",
     "shell.execute_reply": "2024-12-02T06:54:48.043859Z",
     "shell.execute_reply.started": "2024-12-02T06:54:47.951403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train['Emotions'] = df_train['List of classes'].apply(idx2class)\n",
    "df_test['Emotions'] = df_test['List of classes'].apply(idx2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:48.116996Z",
     "iopub.status.busy": "2024-12-02T06:54:48.116111Z",
     "iopub.status.idle": "2024-12-02T06:54:48.122078Z",
     "shell.execute_reply": "2024-12-02T06:54:48.121230Z",
     "shell.execute_reply.started": "2024-12-02T06:54:48.116954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def EmotionMapping(emotion_list):\n",
    "    map_list = []\n",
    "    \n",
    "    for i in emotion_list:\n",
    "        if i in ekman_mapping['anger']:\n",
    "            map_list.append('anger')\n",
    "        if i in ekman_mapping['disgust']:\n",
    "            map_list.append('disgust')\n",
    "        if i in ekman_mapping['fear']:\n",
    "            map_list.append('fear')\n",
    "        if i in ekman_mapping['joy']:\n",
    "            map_list.append('joy')\n",
    "        if i in ekman_mapping['sadness']:\n",
    "            map_list.append('sadness')\n",
    "        if i in ekman_mapping['surprise']:\n",
    "            map_list.append('surprise')\n",
    "        if i == 'neutral':\n",
    "            map_list.append('neutral')\n",
    "            \n",
    "    return map_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:48.314586Z",
     "iopub.status.busy": "2024-12-02T06:54:48.314082Z",
     "iopub.status.idle": "2024-12-02T06:54:48.374576Z",
     "shell.execute_reply": "2024-12-02T06:54:48.373985Z",
     "shell.execute_reply.started": "2024-12-02T06:54:48.314558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train['Mapped Emotions'] = df_train['Emotions'].apply(EmotionMapping)\n",
    "df_test['Mapped Emotions'] = df_test['Emotions'].apply(EmotionMapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:48.515907Z",
     "iopub.status.busy": "2024-12-02T06:54:48.515661Z",
     "iopub.status.idle": "2024-12-02T06:54:48.528914Z",
     "shell.execute_reply": "2024-12-02T06:54:48.527970Z",
     "shell.execute_reply.started": "2024-12-02T06:54:48.515883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train['anger'] = np.zeros((len(df_train),1))\n",
    "df_train['disgust'] = np.zeros((len(df_train),1))\n",
    "df_train['fear'] = np.zeros((len(df_train),1))\n",
    "df_train['joy'] = np.zeros((len(df_train),1))\n",
    "df_train['sadness'] = np.zeros((len(df_train),1))\n",
    "df_train['surprise'] = np.zeros((len(df_train),1))\n",
    "df_train['neutral'] = np.zeros((len(df_train),1))\n",
    "\n",
    "df_test['anger'] = np.zeros((len(df_test),1))\n",
    "df_test['disgust'] = np.zeros((len(df_test),1))\n",
    "df_test['fear'] = np.zeros((len(df_test),1))\n",
    "df_test['joy'] = np.zeros((len(df_test),1))\n",
    "df_test['sadness'] = np.zeros((len(df_test),1))\n",
    "df_test['surprise'] = np.zeros((len(df_test),1))\n",
    "df_test['neutral'] = np.zeros((len(df_test),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:48.696009Z",
     "iopub.status.busy": "2024-12-02T06:54:48.695752Z",
     "iopub.status.idle": "2024-12-02T06:54:48.812728Z",
     "shell.execute_reply": "2024-12-02T06:54:48.811934Z",
     "shell.execute_reply.started": "2024-12-02T06:54:48.695984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise','neutral']:\n",
    "    df_train[i] = df_train['Mapped Emotions'].apply(lambda x: 1 if i in x else 0)\n",
    "    df_test[i] = df_test['Mapped Emotions'].apply(lambda x: 1 if i in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:48.885239Z",
     "iopub.status.busy": "2024-12-02T06:54:48.884954Z",
     "iopub.status.idle": "2024-12-02T06:54:48.900536Z",
     "shell.execute_reply": "2024-12-02T06:54:48.899533Z",
     "shell.execute_reply.started": "2024-12-02T06:54:48.885214Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>ID</th>\n",
       "      <th>List of classes</th>\n",
       "      <th>Len of classes</th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Mapped Emotions</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>27</td>\n",
       "      <td>eebbqej</td>\n",
       "      <td>[27]</td>\n",
       "      <td>1</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>27</td>\n",
       "      <td>ed00q6i</td>\n",
       "      <td>[27]</td>\n",
       "      <td>1</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>2</td>\n",
       "      <td>eezlygj</td>\n",
       "      <td>[2]</td>\n",
       "      <td>1</td>\n",
       "      <td>[anger]</td>\n",
       "      <td>[anger]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>14</td>\n",
       "      <td>ed7ypvh</td>\n",
       "      <td>[14]</td>\n",
       "      <td>1</td>\n",
       "      <td>[fear]</td>\n",
       "      <td>[fear]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>3</td>\n",
       "      <td>ed0bdzj</td>\n",
       "      <td>[3]</td>\n",
       "      <td>1</td>\n",
       "      <td>[annoyance]</td>\n",
       "      <td>[anger]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Class       ID  \\\n",
       "0  My favourite food is anything I didn't have to...    27  eebbqej   \n",
       "1  Now if he does off himself, everyone will thin...    27  ed00q6i   \n",
       "2                     WHY THE FUCK IS BAYLESS ISOING     2  eezlygj   \n",
       "3                        To make her feel threatened    14  ed7ypvh   \n",
       "4                             Dirty Southern Wankers     3  ed0bdzj   \n",
       "\n",
       "  List of classes  Len of classes     Emotions Mapped Emotions  anger  \\\n",
       "0            [27]               1    [neutral]       [neutral]      0   \n",
       "1            [27]               1    [neutral]       [neutral]      0   \n",
       "2             [2]               1      [anger]         [anger]      1   \n",
       "3            [14]               1       [fear]          [fear]      0   \n",
       "4             [3]               1  [annoyance]         [anger]      1   \n",
       "\n",
       "   disgust  fear  joy  sadness  surprise  neutral  \n",
       "0        0     0    0        0         0        1  \n",
       "1        0     0    0        0         0        1  \n",
       "2        0     0    0        0         0        0  \n",
       "3        0     1    0        0         0        0  \n",
       "4        0     0    0        0         0        0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed in id[4], annoyance is mapped to a core emotion-anger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:49.555014Z",
     "iopub.status.busy": "2024-12-02T06:54:49.554695Z",
     "iopub.status.idle": "2024-12-02T06:54:49.568394Z",
     "shell.execute_reply": "2024-12-02T06:54:49.567574Z",
     "shell.execute_reply.started": "2024-12-02T06:54:49.554986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train.drop(['Class', 'List of classes', 'Len of classes', 'Emotions', 'Mapped Emotions'], axis=1, inplace=True)\n",
    "df_test.drop(['Class', 'List of classes', 'Len of classes', 'Emotions', 'Mapped Emotions'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till no tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:50.146927Z",
     "iopub.status.busy": "2024-12-02T06:54:50.146185Z",
     "iopub.status.idle": "2024-12-02T06:54:52.132126Z",
     "shell.execute_reply": "2024-12-02T06:54:52.131304Z",
     "shell.execute_reply.started": "2024-12-02T06:54:50.146892Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')  \n",
    "nltk.download('stopwords')  \n",
    "nltk.download('wordnet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:52.134661Z",
     "iopub.status.busy": "2024-12-02T06:54:52.133897Z",
     "iopub.status.idle": "2024-12-02T06:54:53.442725Z",
     "shell.execute_reply": "2024-12-02T06:54:53.441705Z",
     "shell.execute_reply.started": "2024-12-02T06:54:52.134619Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n",
      "   creating: /usr/share/nltk_data/corpora/wordnet/\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n"
     ]
    }
   ],
   "source": [
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords, punctuation and performing stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:53.445287Z",
     "iopub.status.busy": "2024-12-02T06:54:53.444881Z",
     "iopub.status.idle": "2024-12-02T06:54:53.452740Z",
     "shell.execute_reply": "2024-12-02T06:54:53.451901Z",
     "shell.execute_reply.started": "2024-12-02T06:54:53.445226Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Remove non-alphabetic characters\n",
    "    sentence = re.sub('[^A-Za-z]', ' ', sentence)\n",
    "    # Convert to lowercase and split into words\n",
    "    words = sentence.lower().split()\n",
    "    # Remove stopwords and apply lemmatization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def text_preprocessing_pipeline(text):\n",
    "    '''Cleaning and parsing the text.'''\n",
    "    text = preprocess(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:54:53.455659Z",
     "iopub.status.busy": "2024-12-02T06:54:53.455053Z",
     "iopub.status.idle": "2024-12-02T06:55:00.868223Z",
     "shell.execute_reply": "2024-12-02T06:55:00.867319Z",
     "shell.execute_reply.started": "2024-12-02T06:54:53.455620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train['Text'] = df_train['Text'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:00.869549Z",
     "iopub.status.busy": "2024-12-02T06:55:00.869280Z",
     "iopub.status.idle": "2024-12-02T06:55:01.645197Z",
     "shell.execute_reply": "2024-12-02T06:55:01.644495Z",
     "shell.execute_reply.started": "2024-12-02T06:55:00.869524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test[\"Text\"] = df_test[\"Text\"].apply(text_preprocessing_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:01.646917Z",
     "iopub.status.busy": "2024-12-02T06:55:01.646274Z",
     "iopub.status.idle": "2024-12-02T06:55:01.729929Z",
     "shell.execute_reply": "2024-12-02T06:55:01.729052Z",
     "shell.execute_reply.started": "2024-12-02T06:55:01.646876Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43410.000000\n",
       "mean         6.446487\n",
       "std          3.453379\n",
       "min          0.000000\n",
       "5%           2.000000\n",
       "50%          6.000000\n",
       "97%         13.000000\n",
       "max         33.000000\n",
       "Name: Text, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df_train[\"Text\"]).str.split().str.len().describe(percentiles=[0.05, 0.97])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:01.731246Z",
     "iopub.status.busy": "2024-12-02T06:55:01.730964Z",
     "iopub.status.idle": "2024-12-02T06:55:01.748044Z",
     "shell.execute_reply": "2024-12-02T06:55:01.747025Z",
     "shell.execute_reply.started": "2024-12-02T06:55:01.731219Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>ID</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>favourite food anything cook</td>\n",
       "      <td>eebbqej</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>everyone think he laugh screwing people instea...</td>\n",
       "      <td>ed00q6i</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fuck bayless isoing</td>\n",
       "      <td>eezlygj</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make feel threatened</td>\n",
       "      <td>ed7ypvh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dirty southern wanker</td>\n",
       "      <td>ed0bdzj</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text       ID  anger  disgust  \\\n",
       "0                       favourite food anything cook  eebbqej      0        0   \n",
       "1  everyone think he laugh screwing people instea...  ed00q6i      0        0   \n",
       "2                                fuck bayless isoing  eezlygj      1        0   \n",
       "3                               make feel threatened  ed7ypvh      0        0   \n",
       "4                              dirty southern wanker  ed0bdzj      1        0   \n",
       "\n",
       "   fear  joy  sadness  surprise  neutral  \n",
       "0     0    0        0         0        1  \n",
       "1     0    0        0         0        1  \n",
       "2     0    0        0         0        0  \n",
       "3     1    0        0         0        0  \n",
       "4     0    0        0         0        0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a pre-trained DistilRoBERTa-base model and fine-tuning it for emotion recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:01.749898Z",
     "iopub.status.busy": "2024-12-02T06:55:01.749313Z",
     "iopub.status.idle": "2024-12-02T06:55:14.234984Z",
     "shell.execute_reply": "2024-12-02T06:55:14.234304Z",
     "shell.execute_reply.started": "2024-12-02T06:55:01.749859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"michellejieli/emotion_text_classifier\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:14.236562Z",
     "iopub.status.busy": "2024-12-02T06:55:14.236052Z",
     "iopub.status.idle": "2024-12-02T06:55:14.772555Z",
     "shell.execute_reply": "2024-12-02T06:55:14.771830Z",
     "shell.execute_reply.started": "2024-12-02T06:55:14.236516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:14.776199Z",
     "iopub.status.busy": "2024-12-02T06:55:14.775783Z",
     "iopub.status.idle": "2024-12-02T06:55:14.781797Z",
     "shell.execute_reply": "2024-12-02T06:55:14.780836Z",
     "shell.execute_reply.started": "2024-12-02T06:55:14.776173Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Text', 'ID', 'anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral'],\n",
       "    num_rows: 43410\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labelling the emotion column to a numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:14.782961Z",
     "iopub.status.busy": "2024-12-02T06:55:14.782751Z",
     "iopub.status.idle": "2024-12-02T06:55:16.702240Z",
     "shell.execute_reply": "2024-12-02T06:55:16.701380Z",
     "shell.execute_reply.started": "2024-12-02T06:55:14.782939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492e558a3e914d05918f9fd8bc28aee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea8d82ed4ec49efba809c9145b17770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text', 'ID', 'anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral', 'labels']\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {\n",
    "    \"anger\": 0,\n",
    "    \"disgust\": 1,\n",
    "    \"fear\": 2,\n",
    "    \"joy\": 3,\n",
    "    \"neutral\": 4,\n",
    "    \"sadness\": 5,\n",
    "    \"surprise\": 6\n",
    "}\n",
    "\n",
    "def get_labels(batch):\n",
    "    labels = []\n",
    "    for i in range(len(batch['Text'])):  \n",
    "        for emotion in label_mapping.keys():\n",
    "            if batch[emotion][i] == 1:  \n",
    "                labels.append(label_mapping[emotion])\n",
    "                break\n",
    "    return {'labels': labels}\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    get_labels,  \n",
    "    batched=True,  \n",
    "    batch_size=32  \n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    get_labels,  \n",
    "    batched=True,  \n",
    "    batch_size=32  \n",
    ")\n",
    "\n",
    "print(train_dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:16.703489Z",
     "iopub.status.busy": "2024-12-02T06:55:16.703191Z",
     "iopub.status.idle": "2024-12-02T06:55:19.689128Z",
     "shell.execute_reply": "2024-12-02T06:55:19.688324Z",
     "shell.execute_reply.started": "2024-12-02T06:55:16.703463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Text'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:19.690674Z",
     "iopub.status.busy": "2024-12-02T06:55:19.690331Z",
     "iopub.status.idle": "2024-12-02T06:55:32.917663Z",
     "shell.execute_reply": "2024-12-02T06:55:32.916907Z",
     "shell.execute_reply.started": "2024-12-02T06:55:19.690635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  \n",
    "    evaluation_strategy=\"epoch\",  \n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=8,  \n",
    "    num_train_epochs=6,  \n",
    "    weight_decay=0.01,  \n",
    "    logging_dir='./logs',  \n",
    "    save_total_limit=2,  \n",
    "    save_steps=500  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:32.919586Z",
     "iopub.status.busy": "2024-12-02T06:55:32.918812Z",
     "iopub.status.idle": "2024-12-02T06:55:42.379132Z",
     "shell.execute_reply": "2024-12-02T06:55:42.377967Z",
     "shell.execute_reply.started": "2024-12-02T06:55:32.919540Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:42.380749Z",
     "iopub.status.busy": "2024-12-02T06:55:42.380483Z",
     "iopub.status.idle": "2024-12-02T06:55:44.067833Z",
     "shell.execute_reply": "2024-12-02T06:55:44.067216Z",
     "shell.execute_reply.started": "2024-12-02T06:55:42.380724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:44.069029Z",
     "iopub.status.busy": "2024-12-02T06:55:44.068773Z",
     "iopub.status.idle": "2024-12-02T06:55:44.073240Z",
     "shell.execute_reply": "2024-12-02T06:55:44.072309Z",
     "shell.execute_reply.started": "2024-12-02T06:55:44.069004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:44.074577Z",
     "iopub.status.busy": "2024-12-02T06:55:44.074249Z",
     "iopub.status.idle": "2024-12-02T06:55:45.185098Z",
     "shell.execute_reply": "2024-12-02T06:55:45.184451Z",
     "shell.execute_reply.started": "2024-12-02T06:55:44.074549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:55:45.186488Z",
     "iopub.status.busy": "2024-12-02T06:55:45.186132Z",
     "iopub.status.idle": "2024-12-02T08:02:27.187566Z",
     "shell.execute_reply": "2024-12-02T08:02:27.186902Z",
     "shell.execute_reply.started": "2024-12-02T06:55:45.186451Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b93df4b3444156b86e3754e26192df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112942422222558, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241202_071411-mrifujjg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/krishithiruppathi-shiv-nadar-university/huggingface/runs/mrifujjg' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/krishithiruppathi-shiv-nadar-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/krishithiruppathi-shiv-nadar-university/huggingface' target=\"_blank\">https://wandb.ai/krishithiruppathi-shiv-nadar-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/krishithiruppathi-shiv-nadar-university/huggingface/runs/mrifujjg' target=\"_blank\">https://wandb.ai/krishithiruppathi-shiv-nadar-university/huggingface/runs/mrifujjg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16284' max='16284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16284/16284 48:10, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.042900</td>\n",
       "      <td>1.014379</td>\n",
       "      <td>0.636263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.924100</td>\n",
       "      <td>1.037120</td>\n",
       "      <td>0.640870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>1.032981</td>\n",
       "      <td>0.640501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>1.147758</td>\n",
       "      <td>0.622996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>1.320946</td>\n",
       "      <td>0.614336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.438500</td>\n",
       "      <td>1.442044</td>\n",
       "      <td>0.605860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16284, training_loss=0.7583301097220503, metrics={'train_runtime': 4001.3136, 'train_samples_per_second': 65.094, 'train_steps_per_second': 4.07, 'total_flos': 8626383791447040.0, 'train_loss': 0.7583301097220503, 'epoch': 6.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and Reloading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:29:06.088746Z",
     "iopub.status.busy": "2024-12-02T08:29:06.087938Z",
     "iopub.status.idle": "2024-12-02T08:29:07.134727Z",
     "shell.execute_reply": "2024-12-02T08:29:07.133822Z",
     "shell.execute_reply.started": "2024-12-02T08:29:06.088693Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./emotion_model\n",
      "Model and tokenizer reloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./emotion_model\"\n",
    "\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {output_dir}\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "print(\"Model and tokenizer reloaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluating accuracy and Testing using the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:29:13.976489Z",
     "iopub.status.busy": "2024-12-02T08:29:13.975848Z",
     "iopub.status.idle": "2024-12-02T08:29:41.822850Z",
     "shell.execute_reply": "2024-12-02T08:29:41.821986Z",
     "shell.execute_reply.started": "2024-12-02T08:29:13.976457Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.59%\n",
      "Text: really sorry situation although love name sapphira cirilla scarlett\n",
      "True Label: surprise\n",
      "Predicted Label: surprise\n",
      "----------------------------------------\n",
      "Text: wonderful awful\n",
      "True Label: joy\n",
      "Predicted Label: joy\n",
      "----------------------------------------\n",
      "Text: king fan good luck guy interesting game watch\n",
      "True Label: joy\n",
      "Predicted Label: joy\n",
      "----------------------------------------\n",
      "Text: know thank teaching something today\n",
      "True Label: joy\n",
      "Predicted Label: joy\n",
      "----------------------------------------\n",
      "Text: got bored haunting earth thousand year ultimately moved afterlife\n",
      "True Label: sadness\n",
      "Predicted Label: surprise\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from evaluate import load\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "labels = [\n",
    "    \"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"\n",
    "]\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in tokenized_test_dataset:\n",
    "        inputs = {\n",
    "            \"input_ids\": torch.tensor(sample[\"input_ids\"]).unsqueeze(0).to(device),\n",
    "            \"attention_mask\": torch.tensor(sample[\"attention_mask\"]).unsqueeze(0).to(device),\n",
    "        }\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        pred_class = torch.argmax(logits, dim=-1).item()\n",
    "        predictions.append(pred_class)\n",
    "        \n",
    "        references.append(sample[\"labels\"]) \n",
    "\n",
    "accuracy = metric.compute(predictions=predictions, references=references)\n",
    "print(f\"Accuracy: {accuracy['accuracy'] * 100:.2f}%\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Text: {tokenizer.decode(tokenized_test_dataset[i]['input_ids'], skip_special_tokens=True)}\")\n",
    "    print(f\"True Label: {labels[references[i]]}\")\n",
    "    print(f\"Predicted Label: {labels[predictions[i]]}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Response Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a pre-trained GPT-2 model for adaptive response generation after classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T09:58:29.382678Z",
     "iopub.status.busy": "2024-12-01T09:58:29.382045Z",
     "iopub.status.idle": "2024-12-01T09:58:30.343250Z",
     "shell.execute_reply": "2024-12-01T09:58:30.342532Z",
     "shell.execute_reply.started": "2024-12-01T09:58:29.382638Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(\"SuramyaPokharel/gpt2-response_gen\")\n",
    "gpt2_model = AutoModelForSeq2SeqLM.from_pretrained(\"SuramyaPokharel/gpt2-response_gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T09:58:39.560092Z",
     "iopub.status.busy": "2024-12-01T09:58:39.559234Z",
     "iopub.status.idle": "2024-12-01T09:58:39.910940Z",
     "shell.execute_reply": "2024-12-01T09:58:39.910220Z",
     "shell.execute_reply.started": "2024-12-01T09:58:39.560055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "emotion_model.to(device)\n",
    "gpt2_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model and tokenizer of the LLM used for classification are used to predict emotion of a sentence used and then generate a response according to the input prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T09:58:54.049804Z",
     "iopub.status.busy": "2024-12-01T09:58:54.048960Z",
     "iopub.status.idle": "2024-12-01T09:58:54.056135Z",
     "shell.execute_reply": "2024-12-01T09:58:54.055427Z",
     "shell.execute_reply.started": "2024-12-01T09:58:54.049767Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_emotion(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = torch.argmax(logits, dim=1).item()\n",
    "    emotion_labels = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n",
    "\n",
    "    if predicted_class_idx < len(emotion_labels):\n",
    "        predicted_emotion = emotion_labels[predicted_class_idx]\n",
    "    else:\n",
    "        predicted_emotion = 'unknown'  \n",
    "    \n",
    "    return predicted_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A pre-prompt to lead the actual generated response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:28:22.109893Z",
     "iopub.status.busy": "2024-12-01T10:28:22.109511Z",
     "iopub.status.idle": "2024-12-01T10:28:22.117547Z",
     "shell.execute_reply": "2024-12-01T10:28:22.116733Z",
     "shell.execute_reply.started": "2024-12-01T10:28:22.109861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_response(text, emotion):\n",
    "    if emotion == \"sadness\":\n",
    "        prompt = f\"I'm sorry you're feeling down. Here's a comforting thought:\"\n",
    "    elif emotion == \"anger\":\n",
    "        prompt = f\"I understand you're angry. Let me help with that:\"\n",
    "    elif emotion == \"joy\":\n",
    "        prompt = f\"It's great that you're feeling joyful! Here's something to keep the mood up:\"\n",
    "    elif emotion == \"fear\":\n",
    "        prompt = f\"Don't be afraid. Let's find strength together:\"\n",
    "    elif emotion == \"surprise\":\n",
    "        prompt = f\"Wow, that sounds surprising! Let's dive into it:\"\n",
    "    elif emotion == \"neutral\":\n",
    "        prompt = f\"Here's a neutral perspective:\"\n",
    "    else:\n",
    "        prompt = f\"Based on the emotion {emotion}, here‚Äôs a response:\"\n",
    "\n",
    "    print(f\"Prompt from Chatbot: {prompt}\")\n",
    "    inputs = gpt2_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = gpt2_model.generate(inputs[\"input_ids\"], max_length=100, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "    \n",
    "    response = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:28:22.683889Z",
     "iopub.status.busy": "2024-12-01T10:28:22.683053Z",
     "iopub.status.idle": "2024-12-01T10:28:22.791379Z",
     "shell.execute_reply": "2024-12-01T10:28:22.790550Z",
     "shell.execute_reply.started": "2024-12-01T10:28:22.683855Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion: fear\n",
      "Prompt from Chatbot: Don't be afraid. Let's find strength together:\n",
      "Generated Response: Be strong.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"I'm scared of my teacher\"\n",
    "predicted_emotion = predict_emotion(input_text)\n",
    "print(f\"Predicted Emotion: {predicted_emotion}\")\n",
    "\n",
    "response = generate_response(input_text, predicted_emotion)\n",
    "print(f\"Generated Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:36:18.763474Z",
     "iopub.status.busy": "2024-12-01T10:36:18.763124Z",
     "iopub.status.idle": "2024-12-01T10:36:18.924589Z",
     "shell.execute_reply": "2024-12-01T10:36:18.923798Z",
     "shell.execute_reply.started": "2024-12-01T10:36:18.763441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion: joy\n",
      "Prompt from Chatbot: It's great that you're feeling joyful! Here's something to keep the mood up:\n",
      "Generated Response: You're feeling happy!\n"
     ]
    }
   ],
   "source": [
    "input_text = \"I am so excited for the party\"\n",
    "predicted_emotion = predict_emotion(input_text)\n",
    "print(f\"Predicted Emotion: {predicted_emotion}\")\n",
    "\n",
    "response = generate_response(input_text, predicted_emotion)\n",
    "print(f\"Generated Response: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1060121,
     "sourceId": 1956405,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 136584929,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
